<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS 598: Expansion, Codes, and Optimization</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #fff5e6; /* Light orange background */
            color: #333;
        }
        header, footer {
            background-color: #ff8c00; /* Darker orange */
            color: #fff;
            text-align: center;
            padding: 1rem 0;
        }
        header h1 {
            margin: 0.5rem 0;
        }
        section {
            background-color: #fff;
            margin: 1rem auto;
            padding: 2rem;
            max-width: 800px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        h2 {
            color: #ff8c00; /* Orange for headings */
        }
        ul {
            list-style-type: none;
            padding: 0;
        }
        li {
            margin-bottom: 0.5rem;
            padding-left: 1rem;
            text-indent: -1rem;
        }
        li:before {
            content: "â€“ "; /* Unicode en dash */
            padding-right: 5px;
            color: #ff8c00; /* Orange for bullet points */
        }
        p, li {
            line-height: 1.6;
        }
    </style>
</head>
<body>
    <header>
        <h1>CS 598: Expansion, Codes, and Optimization both Classical and Quantum</h1>
        <p><strong>When:</strong> 11:00am-12:15pm Tuesdays and Thursdays (Fall 2024)</p>
        <p><strong>Where:</strong> 1043 Sidney Lu Mech Engr Bldg, University of Illinois Urbana-Champaign</p>
	<p><strong>Instructor:</strong> <a href="https://granha.github.io"> Fernando Granha Jeronimo </a> </p>
	<p><strong>Office Hours:</strong> After class or by appointment</p>		
    </header>

    <section>
        <h2>Course Description</h2>
        <p>The goal of this graduate topics course is to take students from the rudiments all the way
        to some parts of the research frontiers of expansion, coding theory, and optimization both
        from a classical and quantum perspective.</p>
    </section>

    <section>
        <h2>Main Topics</h2>
        <ul>
            <li><strong>Expansion:</strong> Expander graphs combine two opposing properties of being well-connected yet
            sparse. This powerful combination leads to a variety of applications in CS (and mathematics)
              such as error correction, hardness of approximation, fast algorithms, sampling, etc. Recently, several notions
	      of high-dimensional expansion appeared, leading to exciting discoveries. </li>
            <li><strong>Coding theory:</strong> Codes are "robust" collections of strings that not only have implications
            for protection against errors in communication and storage, but they also have connections
            to diverse fields such as complexity theory, expansion, etc. Recently, many breakthrough
            constructions of codes were discovered, such as explicit binary codes close to the GV bound,
            good LTCs, and good qLDPC.</li>
            <li><strong>Optimization:</strong> Convex programming, in particular, linear programming (LP) and semi-definite programming (SDP),
            are at the heart of many efficient algorithms. The use of powerful SDP hierarchies such as the Sum-of-Squares
            hierarchy has recently found many algorithmic applications.</li>
        </ul>
    </section>

    <section>
        <h2>Course Phases</h2>
        <article>
            <h3>Phase 1</h3>
            <p>In this initial phase, we will cover some foundational topics of these fields which may include some of the following:</p>
            <ul>
                <li>Expanders: Notions of expansion, Random Walks, Cheeger's inequality, Cayley graphs of Abelian groups, Zig-zag construction, Ramanujan Graphs</li>
                <li>Coding Theory: Reed Solomon, Reed Muller, Hadamard, LDPC, Tanner, and Quantum CSS Codes, Operations: code concatenation, AEL, tensor, Some code bounds: GV bound, MRRW, Singleton, etc, List Decoding</li>
                <li>Fourier Analysis: Basics (Fourier decomposition, Parseval, etc), BLR, biased distributions and codes, Hypercontractivity</li>
                <li>Optimization: Linear programming (Delsarte's LP combining codes, Fourier analysis and LPs), Semi-definite programming, and Sum-of-Squares (CSPs on Expanders and a local-to-global phenomenon)</li>
                <li>Spectral graph theory: Sensitivity Conjecture (signing, interlacing, etc), Johnson scheme (a complete analog of simplicial HDXs)</li>
            </ul>
        </article>
        <article>
            <h3>Phase 2</h3>
            <p>In this second phase, we will cover some recent topics at the research frontiers which may include some of the following:</p>
            <ul>
                <li>Dinur's PCP by gap amplification</li>
                <li>Explicit balanced codes close to the GV bound by Ta-Shma</li>	      
                <li>Locally Testable Codes, Left-Right Cayley Complexes, c^3-LTC of Dinur et al</li>
                <li>Good quantum LDPC Codes, Quantum Tanner Codes</li>
                <li>Locally Decodable Codes, Matching Vector Codes</li>
                <li>Bipartite Ramanujan graphs (2-lifts MSS'14)</li>
                <li>High-dimensional expanders: Random walks (Up and Down walks), Trickle-down, Expansion of bases exchange of Matroids</li>
            </ul>
        </article>
        <article>
            <h3>Phase 3</h3>
            <p>In this last phase, we will have project presentations. Topics for projects will be selected as we transition from phase 1 to phase 2, with several suggestions available and students encouraged to consult with the instructor.</p>
            <h4>Topics for Projects</h4>
            <p>Possible topics include, but are not limited to:</p>
            <ul>
                <li><strong>Classical:</strong> Agreement Expansion, HDX constructions, Derandomizing Space Bounded Computation, Tree codes, Global Hypercontractivity, Lower bounds on LCCs, Strong bounds for 3-APs, Insertions and Deletions, Reed Muller against BEC and BSC.</li>
                <li><strong>Quantum:</strong> Quantum PCP, Locally Testable Quantum Codes, SYK and Sum-of-Squares, Pseudorandom Unitaries, Quantum Expanders.</li>
            </ul>
        </article>
    </section>


    <section>
      <h2>Lectures</h2>
      Lecture notes will be posted tentatively every week after classes.
       Notes <a href="doc/discovering_expansion_notes.pdf">here</a> (under construction).
	<ul>
	  <li><b>Lecture 1:</b> Overview of the course, some notions of expansion (e.g., edge and vertex expansion), recalling the spectral theorem from linear algebra,
	    and pseudorandom properties of expanders (e.g., expander mixing lemma). </li>
	  <li><b>Lecture 2:</b> We recalled the previous lecture, introduced the random walk operator, proved mixing bounds of random walks,
	    introduced Cheeger's inequality, and very briefly mentioned the Laplacian matrix. </li>
	  <li><b>Lecture 3:</b> Quadratic form and its connection to the spectral decomposition. Optimization/variational characterization of
	      eigenvalues, including the Courant-Firscher-Weyl min-max theorem. Relating the spectrum of principal submatrices (in particular, induced subgraphs)
	    via Cauchy interlacing theorem. Recursive definition of the adjacency matrix of the Boolean hypercube. Introduced Boolean functions and two complexity
	    measures: sensitivity and block sensitivity. Stated the (now resolved) sensitivity conjecture.
	  </li>
	  <li><b>Lecture 4:</b> Introduced Fourier analysis of Boolean functions with characters, their orthogonality, and Fourier decomposition. Introduced the complexity
	    measures of degree and approximate degree. Discussed the classical and quantum query model with the decision trees and quantum oracle model. Introduced
	    associated complexity measures D(f) and Q(f), and their connection to degree and approximate degree. Polynomial relation among complexity measures. Implications
	    to Grover's algorithm and quantum speed-up for total functions. Introduced edge signing of graphs. Presented Huang's proof of the sensitivity conjecture using
	    the spectral graph theory toolkit developed so far.
	  </li>
	  <li><b>Lecture 5:</b> Various properties of the Fourier transform (Parseval, variance, etc). Convolution and its Fourier transform. Characters as homomorphisms.
	    Characters as the eigenfunctions of the Boolean hypercube. Property testing with the case of linearity testing. The BLR linearity test, and its Fourier analytic
	    proof.
	  </li>
	  <li><b>Lecture 6:</b> A case of study of pseudorandomness through the fundamental notion of  epsilon-biased distributions and their power in fooling some classes of functions.
	    Cayley graphs, an important class of graphs defined from a group and a set of generators. A reminder of characters as eigenfunctions of Cayley graphs with the case of Z_2^n.
	    The equivalence of an epsilon-biased distribution and a two-sided Cayley expander over Z_2^n. Started introducing coding theory with the notions of code, Hamming distance, and rate.
	  </li>	  
	  <li><b>Lecture 7: </b> More on the basics of coding theory. Linear codes as an important
	    class of codes, and some of their properties. The Hadamard code with its basic properties
	    and its connection to characters and the Fourier transform. More on the local testability of 
	    the Hadamard code.
	  </li>     
	  <li><b>Lecture 8: </b> Generator matrix of linear codes. Extending the equivalence of  epsilon-biased distributions and expanders to also include epsilon-balanced codes. Code as an independent set problem. Gilbert-Varshamov (GV) bound for general codes via graph theory. GV bound for linear codes and the existence of small support epsilon-biased distributions. Entropy and its relation to the volume of Hamming balls. Rate upper bounds via the Hamming bound.
	  </li>
	  <li><b>Lecture 9: </b> Proved another impossibility result known as the Singleton bound.
	    Discussed the mantra that low-degree polynomials have few roots (a simple and yet central theme in coding theory and TCS). Introduced the Reed-Solomon (RS) codes and showed that they achieve the Singleton bound (an example of MDS codes). Discussed the generating matrix of RS codes. Introduced the notion of the dual of a linear code and its connection to the parity check matrix of a code. Introduced the notion of LDPC codes and started discussing how one might try to construct good families of LDPC codes based on expanders.
	  </li>        	  
	  <li><b>Lecture 10: </b> Flipped classroom: you constructed a family of good LDPC Tanner codes based on bipartite spectral expander graphs. You leveraged a local constant-sized code
	    C_0 into a family of good codes of growing blocklength (this is an example of the local-to-global phenomenon of expanders). You proved its rate and established its minimum distance
	    (try to iron the details out now).
	  </li>
	  <li><b>Lecture 11: </b> We recalled the Tanner code construction from last class. Discussed tensor product codes and their parameters, and how the expander based Tanner codes can be seen as "derandomization" of tensor codes. Next, we moved to explicit constructions of bounded degree families of expander graphs based on the Zig-Zag graph product. Introduced the replacement product of graphs, the permutation matrix associated with the edges of the outer graphs, and the edges of the Zig-Zag (short-long-short). Finally, we gave a matrix description of the (normalized) adjacency matrix of the Zig-Zag product.
	  </li>          
	  <li><b>Lecture 12: </b> Flipped classroom: after we recalled the Zig-Zag product, we proceeded to the analysis of its expansion. You computed a bound on its two-sided spectral expansion by splitting the analysis into a few cases (I guided you from a distance towards 
	    the original analysis of the Zig-Zag which has beautiful interpretations though it is not the shortest). Then, we discussed how to use this product recursively to build an entire explicit family of bounded degree expanders. We also briefly mentioned that by tensoring the graphs, one can also get strongly explicit constructions. 
	  </li>
	  <li><b>Lecture 13: </b> We recalled some of the various explicit pseudorandom constructions from class so far. Then, we proceeded to find an explicit construction of epsilon-balanced codes starting from our explicit construction toolkit. We discussed how XOR can be used to reduce bias, which, in particular, amplifies the distance. The first naive dense construction led to a vanishing rate. We briefly discussed that a randomized construction leads to (near) optimal rate, but it is non-explicit.  Then, we discussed how to use expander walk-based XOR amplification as an attempt to derandomize the random construction.
	  </li>    

	  <li><b>Lecture 14: </b> Flipped classroom: We recalled the expander walk-based XOR amplification from the last class. You first mapped the bias reduction computation to a 
	    linear algebraic problem involving the normalized adjacency matrix of the expander. Then, you showed an exponential bias reduction in the walk length. Finally, we concluded by showing that, with a (near) Ramanujan expander, this explicit construction yields explicit epsilon-balanced codes of rate Omega(epsilon^{4+o(1)}).
	  </li>    

	  <li><b>Lecture 15: </b> We discussed the problem of s-t connectivity on undirected graphs and its connection to space-bounded computation. We discussed how this problem can be solved using O(log(n)) space on bounded degree expanders. We discussed how our Zig-Zag toolkit (derandomization of degree) together with graph powering naturally leads to a strategy to solve this problem in O(log(n)) (try to implement this strategy now). Then we went back to coding theory to discuss the important concept of list decoding as a way of going beyond the unique decoding radius. We stated the list decoding capacity theorem, which establishes the best list decoding radius vs rate trade-offs. Flipped classroom: you
	    correctly guessed the trade-offs and then you proved the theorem using the probabilistic method.
	  </li>    

	  <li><b>Lecture 16: </b> We recalled some of the various notions of expansion for graphs we have seen so far in class. Then we initiated a discussion on how to extend our expansion zoo. We started with generalizations for hypergraphs. We introduced the notion of simplicial complexes and links. We introduced the complete complex of "dimension" 'd' as the hypergraph analog of complete graphs and showed how this complex leads to many well-known graphs on the Johnson scheme (Johnson, Kneser graphs, etc).  We presented a high-dimensional expansion notion of link spectral expanders (one-sided and two-sided). Mentioned how it is intended to capture derandomizations of the (ideal) complete complex. Next, we introduced the notion of quantum expanders and how they can be seen as natural quantum generalizations of expander graphs.
	  </li>

	  <li><b>Lecture 17: </b> We recalled the definitions of high-dimensional expanders and quantum expanders from the last class. Next, we switched gears to convex optimization. 
	    First, we gave a linear programming (LP) relaxation for the independence number of a graph. Then, we discussed how allowing simple-looking quadratic constraints leads to 0/1 optimization and the ability to decide NP-complete problems. Next, we introduced semi-definite programming (SDP) and how it can emulate some relaxed forms of quadratic constraints by optimizing over positive semi-definite (PSD) matrices. We discussed how SDPs are closely connected to quantum since the very description of a quantum state is a PSD matrix of trace 1. We designed a simple SDP to approximate the acceptance probability of a QMA verifier (quantum version of NP), from which we deduced that QMA is contained in EXP (note that better upper bounds are known). Then, we returned to graphs to design an SDP relaxation for the independence number. In doing so, we deduced (a formulation of) the LovÃ¡sz theta function. Finally, we started to set the stage for more powerful forms of SDPs in the form of the Sum-of-Squares SDP hierarchy. Initially, we conducted a thought experiment assuming that we were able to evaluate the expectation of any given function on the uniform distribution over optimum solutions (in this case a distribution over maximum independent sets of a graph). We observed axioms that the expectation operator (seen as a map from functions to the reals) satisfies. We started to discuss natural ways to relax the expectation operator, which led to the pseudo-expectation operator view of the Sum-of-Squares hierarchy.
	  </li>       
	  <li><b>Lecture 18: </b> We recalled concepts from last class: the LP relaxation for the independence number,  the LovÃ¡sz theta function, and the initial discussion on the pseudo-expectation view of the Sum-of-Squares (SoS) SDP hierarchy. We proceeded to fully develop the pseudo-expectation view of SoS hierarchy for the independence number of a graph. Two key shortcomings of pseudo-expectation operator (at level D of the hierarchy) are: (1) it is only defined for polynomials of degree at most D (larger degree polynomials cannot be evaluated), and (2) it is only guaranteed to be non-negative on polynomials that can be written as sum-of-squares (of polynomials of degree at most D/2) rather than being non-negative for any non-negative function. We divided the properties of the pseudo-expectation operator into problem-independent and problem-specific. Next, we move on to explain how the pseudo-expectation operator view is equivalent to a "big" SDP. For this, we introduced the notion of the (pseudo-)moment matrix (whose entries are (pseudo)-expectations of monomials of degree at most D). Next, we observed that for "true" distributions, the moment matrix is PSD, so we can require the pseudo-moment matrix to also be PSD. We showed how several properties of the pseudo-expectation operator can be expressed as constraints on the (pseudo-)moment matrix. 
	  </li>
	  <li><b>Lecture 19: </b> No class (FOCS).
	  </li>
	  <li><b>Lecture 20: </b> SoS Halloween Hackathon (Breaking the SoS daunting notation barrier of entry). Â As a group you completed 4 tasks. First, you recalled the pseudo-expectation formalism of the SoS hierarchy for the independence number (~10 minutes). Second, you recalled the (pseudo-)moment matrix formalism of the SoS hierarchy (~10 minutes). Third, you proved that the (pseudo-)moment matrix being PSD implies that the pseudo-expectation is non-negative on SoS polynomials (assuming its degree is at most D, so things are well-defined). Fourth, you gave a Sum-of-Squares proof of the widely used Cauchy-Schwarz inequality (this means that the SoS hierarchyÂ  "automatically" applies this inequality for you). You did not need to use any of your 4 yes/no questions to me, nor the one yes/no question to our pseudo-student. Finally, you quickly presented your findings to me and everything was correct! ;)</li> Â Â 
	</ul>
    </section>    

    <section>
        <h2>Grading</h2>
        <p>This is an advanced graduate topics course, so the primary goal is to develop your research maturity and increase your knowledge and skills. Grades will be a secondary concern. We do expect you to seriously attack your chosen research project, but there is no requirement of a tangible outcome.</p>
        <h3>Policy</h3>
 <ul>
 <li> Project: 80% (updated details!)<ul>
     <li> This will consist in selecting a research problem or paper related to the course in consultation with the instructor.
       Students can either work in pairs or individually. The outcome should be a short research paper on the chosen topic (this
       can range from a survey to an original result ;), and a presentation towards the end of the course.
       In summary, a project will consist of the following:
       <ul>
	 <li> Selection of the research topic: consult the instructor to find a problem or paper aligned with your interests
	   and the scope of the course. This can occur at any point (ideally, as we transition from phase 1 to 2).
	 </li>
	 <li> Mid-project feedback: collect the instructor's feedback on the progress of the project at approximately
	   1 month before the end of the course.
	 </li>
	 <li> Project supervision: you are welcome and encouraged to interact with me once a week for ~30 minutes. To be sure you find me, please schedule
	      office hours via email. Otherwise, I should be tentatively mostly around on Thursdays and Fridays afternoons.
	      My (temporary) office is 4336 at Siebel Center.
	 </li>	 
	 <li> Outcomes: research paper (~10 pages) + presentation towards the end of the course (~15-20 minutes per project).</li>
       </ul>
     </li>
   </ul>
 </li> 
 <li> Participation: 20% </li>
 This includes attendance, curiosity, asking questions during class or office hours, etc.
</lu>
</section>


    <section>
        <h2>Additional Material</h2>
        <p>We will not follow any particular book or resource in this course. However, there are many great additional resources for further study, depending on your interests.
	A sample is given below (in no particular order).</p>
	<ul>
	  <li> <a href="https://www.cs.huji.ac.il/~nati/PAPERS/expander_survey.pdf">Expander Graphs and Their Applications</a> survey by Hoory, Linial and Widgerson </li>
	  <li> <a href="https://lucatrevisan.github.io/books/expanders-2016.pdf">Graph Partitioning, Expanders and Spectral Methods</a> lecture notes by Trevisan </li>
	  <li> <a href="https://www.wisdom.weizmann.ac.il/~dinuri/courses/22-HDX/index.htm">High Dimensional Expanders</a> course by Dinur </li>
	  <li> <a href="https://arxiv.org/pdf/1712.02526">High Dimensional Expanders</a> survey by Lubotzky</li>
	  <li> <a href="http://cs-www.cs.yale.edu/homes/spielman/sagt/sagt.pdf">Spectral and Algebraic Graph Theory</a> book draft by Spielman </li>
	  <li> <a href="https://courses.cs.washington.edu/courses/cse599s/22wi/">Modern Spectral Graph Theory</a> course by Oveis Gharan </li>
	  <li> <a href="https://cs.uwaterloo.ca/~lapchi/cs860-2019/notes.html">Spectral Graph Theory</a> course by Lau </li>
	  <li> <a href="https://cse.buffalo.edu/faculty/atri/courses/coding-theory/book/web-coding-book.pdf">Essential Coding Theory</a> book by Guruswami, Rudra and Sudan</li>
	  <li> <a href="https://www.youtube.com/watch?v=vfjN7MmSB6g&list=PLkvhuSoxwjI_UudECvFYArvG0cLbFlzSr">Algebraic Error Correcting Codes</a> course by Wootters</li>
	  <li> <a href="https://people.eecs.berkeley.edu/~venkatg/teaching/ECC-fall22/">Advances in Error-Correcting Codes</a> course by Guruswami</li>
	  <li> <a href="https://www.youtube.com/playlist?list=PLm3J0oaFux3ZYpFLwwrlv_EHH9wtH6pnX">CS Theory Toolkit</a> course by O'Donnell </li>
	  <li> <a href="https://www.nowpublishers.com/article/Details/TCS-010">Pseudorandomness</a> book by Vadhan</li>
	  <li> <a href="https://www.tcs.tifr.res.in/~ramprasad/courses/2023-Pseudorandomness/">Pseudorandomness</a> course by Harsha and Saptharishi </li>
	  <li> <a href="https://www.gilcohen.org/2023-pseudorandomness">Pseudorandomness</a> course by Cohen </li>
	  <li> <a href="https://arxiv.org/pdf/2105.10386">Analysis of Boolean Functions</a> book by O'Donnell </li>
	  <li> <a href="https://www.youtube.com/watch?v=JIruJ8edYYM&list=PLm3J0oaFux3YypJNaF6sRAf2zC1QzMuTA">Analysis of Boolean Functions</a> course by O'Donnell </li>
	  <li> <a href="https://www.cs.tau.ac.il//~amnon/Classes/2018-Space/class.htm">Space-Bounded Computation</a> course by Ta-Shma </li>
	  <li> <a href="https://www.sumofsquares.org/public/index.html">Proofs, beliefs, and algorithms through the lens of sum-of-squares</a> course by Barak and Steurer </li>
	  <li> <a href="https://www.youtube.com/watch?v=tMWZw9f3J48&list=PL3NB_Sd9CrX-6CeApf12demgpe2PO4k8c">Proofs vs Algorithms: The Sum-of-Squares Method</a> course by Kothari </li>
	  <li> <a href="http://users.cms.caltech.edu/~vidick/teaching/286_qPCP/index.html">Around the quantum PCP conjecture</a> course by Vidick </li>
	  <li> <a href="https://people.eecs.berkeley.edu/~jswright/quantumcodingtheory24/">Quantum Coding Theory</a> course by Wright</li>
	  <li> <a href="https://www.cs.umd.edu/class/spring2024/cmsc858G/QECCbook-2024-ch1-8.pdf">Surviving as a Quantum Computer in a Classical World</a> book by Gottesman</li>
	  <li> <a href="https://pirsa.org/18010047">Quantum Error Correction</a> course by Gottesman and Yoshida</li>
	  <li> <a href="https://people.cs.uchicago.edu/~laci/HANDOUTS/linalgbook.pdf">Discover Linear Algebra</a> book draft by Babai in collaboration with Halford</li>
	</lu>
    </section>    

    <section>
        <h2>Pre-requisites</h2>
        <p>Mathematical maturity is the only pre-requisite. Having taken some proof-based courses in CS or math may be extremely helpful.</p>
    </section>

    <footer>
      <p class="disclaimer">Special Accommodations: if you need any special accommodation, please contact the instructor.</p>
      <p class="disclaimer">Inclusiveness Note: everyone is welcome to attend this course. TCS is important, fun and for everyone!</p>
      <p class="disclaimer">Disclaimer: This page is currently under construction and subject to change.</p>      
    </footer>
</body>
</html>
